In this context, we provided (CSUR'23) a comprehensive and scientifically sound comparison of IS methods applied to Text Classification, considering several classification solutions and many datasets, answering questions that reveal an enormous unfulfilled potential for IS solutions. We also proposed (SIGIR'23) a two-step framework aimed at large datasets with a particular focus on Transformer architectures. Our solution managed to reduce the training sets by almost 30% on average while maintaining the same levels of effectiveness in all datasets, with speedup improvements of 37% (up to 70%), scaling for datasets with hundreds of thousands of documents.